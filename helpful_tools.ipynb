{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b66a9036",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec809250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import os, openai\n",
    "API_KEY = os.getenv('BOSON_API_KEY')\n",
    "client = openai.Client(\n",
    "    api_key=API_KEY,\n",
    "    base_url=\"https://hackathon.boson.ai/v1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eeffd656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from pathlib import Path\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "path = kagglehub.dataset_download(\"uwrfkaggler/ravdess-emotional-speech-audio\")\n",
    "import pandas as pd\n",
    "\n",
    "fs = Path(path).glob('**/*.wav')\n",
    "df = pd.DataFrame({'f': [str(f) for f in fs]})\n",
    "df['stem'] = df.f.str.extract(r'.*\\\\(.*).wav')\n",
    "df2 = pd.DataFrame(df.stem.str.split('-').tolist(), columns=['modality', 'vocal', 'emotion', 'intensity', 'statement', 'repetition', 'actor']).astype(int)\n",
    "df_total = df.merge(df2, left_index=True, right_index=True)\n",
    "statements = [\"Kids are talking by the door\", \"Dogs are sitting by the door\"]\n",
    "emotions = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']\n",
    "\n",
    "df_total['emotion'] = df_total.emotion.apply(lambda x: emotions[x - 1])\n",
    "df_total['statement'] = df_total.statement.apply(lambda x: statements[x - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe16c1",
   "metadata": {},
   "source": [
    "### Emotion Tagged Audio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7f427a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audio(transcript, system_prompt=None, additional_messages=None, temperature=0.9, \n",
    "                   top_p=0.95, top_k=50, max_tokens=2048, out_name='out.wav', **kwargs):\n",
    "    additional_messages = [] if additional_messages is None else additional_messages\n",
    "    system_prompt = system_prompt or 'Generate speech based on the provided sample and transcript. <|scene_desc_start|>The audio is recorded in a quiet room with no noise. The speech is clearly audible and loud.<|scene_desc_end|>'\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"higgs-audio-generation-Hackathon\",\n",
    "        messages=[  \n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "        ] + additional_messages + [{'role': 'user', 'content': transcript}],\n",
    "        modalities=[\"text\", \"audio\"],\n",
    "        max_completion_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        stream=False,\n",
    "        stop=[\"<|eot_id|>\", \"<|end_of_text|>\", \"<|audio_eos|>\"],\n",
    "        extra_body={\"top_k\": top_k},\n",
    "        **kwargs\n",
    "    )  \n",
    "    save_audio(resp, out_name)\n",
    "\n",
    "def extract_samples(n_samples=None, **kwargs):\n",
    "    mask = df_total.f.notna()\n",
    "    for k, v in kwargs.items():\n",
    "        mask &= (df_total[k] == v)\n",
    "    samples = []\n",
    "    masked = df_total[mask]\n",
    "    n_samples = min(len(masked), n_samples) if n_samples is not None else len(masked)\n",
    "    for _, sample in df_total[mask].sample(n_samples).iterrows():\n",
    "        samples += [{'role': 'user', 'content': sample.statement}, \n",
    "            {'role': 'assistant', 'content': [to_audio(sample.f, min_vol=-30)]}]\n",
    "    return samples\n",
    "\n",
    "transcript = r\"\"\"Okay look, I know last round looked bad, but hear me out. I voted early because I didn’t want to look suspicious just sitting there waiting for everyone else to decide. I figured if I threw in a vote fast, we’d get some momentum going and actually talk about something. Then everyone started jumping on the same person, and by the time I thought about changing, the round was basically over.\n",
    "And yeah, I was quiet after that, but that’s because everyone was talking over each other. I didn’t wanna add noise. I’m paying attention, though. I’ve got a few guesses now that I’ve seen who defended who. If I was mafia, do you really think I’d have played it that sloppy?\"\"\"\n",
    "\n",
    "generate_audio(transcript, out_name='neutral.wav', \n",
    "               additional_messages=extract_samples(actor=1, emotion='neutral')) ### neutral\n",
    "generate_audio(transcript, out_name='really_angry.wav', \n",
    "               additional_messages=extract_samples(actor=1, emotion='angry', intensity=2)) ### strong angry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640fbe4a",
   "metadata": {},
   "source": [
    "### Audio to Semantic Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddc7362c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The speaker's tone is defensive and anxious as they earnestly try to justify their actions from the previous round. They explain their reasoning for voting early, expressing regret that they were unable to change their mind as the discussion became chaotic. The emotional undercurrent is one of pleading and sincerity, culminating in a rhetorical question that seeks to convince the listener of their competence and innocence, revealing a deep-seated worry about being perceived as a poor player.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def semantic_distillation(audio, verbose=False, max_tokens=4096, temperature=0.2, top_p=0.95):\n",
    "    messages = [\n",
    "            {\"role\":\"system\",\"content\":\"You are a helpful assistant.\"},\n",
    "            {\"role\":\"user\",\"content\":[\n",
    "                {\"type\":\"audio_url\",\"audio_url\": {\"url\":upload_temp(audio)}},\n",
    "                {\"type\":\"text\",\"text\":f\"Write a short description about the emotional information in the audio.\"}\n",
    "            ]},\n",
    "        ]\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"Qwen3-Omni-30B-A3B-Thinking-Hackathon\",\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        stream=False,\n",
    "    )   \n",
    "    return process_resp(resp, verbose=verbose)\n",
    "\n",
    "semantic_distillation('really_angry.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74283a6",
   "metadata": {},
   "source": [
    "### ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98835980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, look, I know last round looked bad, but hear me out. I voted early because I didn't want to look suspicious just sitting there waiting for everyone else to decide. I figured if I threw in a vote fast, we'd get some momentum going and actually talk about something. Then everyone started jumping on the same person, and by the time I thought about changing, the round was basically over. And yeah, I was quiet after that, but that's because everyone was talking over each other. I didn't want to add noise. I'm paying attention though. I've got a few guesses now that I've seen who defended who. If I was mafia, do you really think I'd have played it that sloppy?\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def asr(audio, verbose=False, max_tokens=4096, temperature=0.2, top_p=0.95):\n",
    "    messages = [\n",
    "            {\"role\":\"system\",\"content\":\"You are a helpful assistant.\"},\n",
    "            {\"role\":\"user\",\"content\":[\n",
    "                {\"type\":\"audio_url\",\"audio_url\": {\"url\":upload_temp(audio)}},\n",
    "                {\"type\":\"text\",\"text\":f\"Transcribe this audio.\"}\n",
    "            ]},\n",
    "        ]\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"Qwen3-Omni-30B-A3B-Thinking-Hackathon\",\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        stream=False,\n",
    "    )   \n",
    "    return process_resp(resp, verbose=verbose)\n",
    "\n",
    "asr('really_angry.wav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
